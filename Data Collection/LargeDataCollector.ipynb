{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfQOyEHj8DWNF8YjwrY3hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivendrra/SmallLanguageModel-project/blob/main/Data%20Collection/LargeDataCollector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AapZLRdU5i3u"
      },
      "outputs": [],
      "source": [
        "# run this first always!\n",
        "!pip install python-dotenv\n",
        "!pip install youtube-transcript-api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "start_time = timeit.default_timer()"
      ],
      "metadata": {
        "id": "7l_mZneW5o7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_Id_Json  = [\n",
        "  \"UCb_MAhL8Thb3HJ_wPkH3gcw\", #phil edwards\n",
        "  \"UCA295QVkf9O1RQ8_-s3FVXg\", #aevy tv\n",
        "  \"UCpFFItkfZz1qz5PpHpqzYBw\", #nexpo\n",
        "  \"UCY1kMZp36IQSyNx_9h4mpCg\", #mark robber\n",
        "  \"UCA19mAJURyYHbJzhfpqhpCA\", #action lab shorts\n",
        "  \"UCqnbDFdCpuN8CMEg0VuEBqA\", #new york times\n",
        "  \"UCddiUEpeqJcYeBxX1IVBKvQ\", #the verge\n",
        "  \"UCcefcZRL2oaA_uBNeo5UOWg\", #y-combinator\n",
        "  \"UCLXo7UDZvByw2ixzpQCufnA\", #vox\n",
        "  \"UCsQoiOrh7jzKmE8NBofhTnQ\", #varun mayya\n",
        "  \"UCUyvQV2JsICeLZP4c_h40kA\", #thomas flight\n",
        "  \"UCvjgXvBlbQiydffZU7m1_aw\", #the coding train\n",
        "  \"UCRI00CwLZdLRCWg5BdDOsNw\", #canadian lad\n",
        "  \"UCEIwxahdLz7bap-VDs9h35A\", #steve mould\n",
        "  \"UC4bq21IPPbpu0Qrsl7LW0sw\", #slidebean\n",
        "  \"UCR1IuLEqb6UEA_zQ81kwXfg\", #real engineering\n",
        "  \"UCIlU5KDHKFSaebYviKfOidw\", #newsthink\n",
        "  \"UCtYKe7-XbaDjpUwcU5x0bLg\", #neo\n",
        "  \"UCBJycsmduvYEL83R_U4JriQ\", #mkbdh\n",
        "  \"UCRcgy6GzDeccI7dkbbBna3Q\", #lemmino\n",
        "  \"UC3_BakzLfadvFrsnClMFWmQ\", #john coogan\n",
        "  \"UCmGSJVG3mCRXVOP4yZrU1Dw\", #johnny harris\n",
        "  \"UCFN6lQpfY8XIRdhv9G-f4bg\", #henry belcaster\n",
        "  \"UConJDkGk921yT9hISzFqpzw\", #freethink\n",
        "  \"UClWTCPVi-AU9TeCN6FkGARg\", #EO\n",
        "  \"UCyHJ94JzwY92NsBVzJ2aE3Q\", #econ\n",
        "  \"UCTqEu1wZDBju2tHkNP1dwzQ\", #earthrise\n",
        "  \"UCcabW7890RKJzL968QWEykA\", #CS 50\n",
        "  \"UCamLstJyCa-t5gfZegxsFMw\", #colin and samir\n",
        "  \"UC415bOPUcGSamy543abLmRA\", #cleo abraham\n",
        "  \"UCpMcsdZf2KkAnfmxiq2MfMQ\", #arvin ash\n",
        "  \"UCqVEHtQoXHmUCfJ-9smpTSg\", #answer in progress\n",
        "  \"UCYO_jab_esuFRV4b17AJtAw\", #3blue1brown\n",
        "  \"UCHnyfMqiRRG1u-2MsSQLbXA\", #veritasium\n",
        "  \"UCsXVk37bltHxD1rDPwtNM8Q\", #kurzgesagt\n",
        "  \"UC9RM-iSvTu1uPJb8X5yp3EQ\", #wendover\n",
        "  \"UCZaT_X_mc0BI-djXOlfhqWQ\", #vice news\n",
        "  \"UCMiJRAwDNSNzuYeN2uWa0pA\", #mrwhosetheboss\n",
        "  \"UCHpw8xwDNhU9gdohEcJu4aA\", #theguardian\n",
        "  \"UCK7tptUDHh-RYDsdxO1-5QQ\", #wallstreetjournal\n",
        "  \"UCsooa4yRKGN_zEE8iknghZA\", #ted-ed\n",
        "]"
      ],
      "metadata": {
        "id": "OClda9dg5rsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "api_key = os.getenv('yt_secret_key')"
      ],
      "metadata": {
        "id": "OFJpbekO5tab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "from youtube_transcript_api import TranscriptsDisabled, YouTubeTranscriptApi\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(filename='youtube_fetch.log', level=logging.ERROR)\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)"
      ],
      "metadata": {
        "id": "3xB6aQ5O5wMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "videoNo = 0\n",
        "for links in channel_Id_Json:\n",
        "  next_page_token = None\n",
        "  videoIds = []\n",
        "\n",
        "  while True:\n",
        "    channelRes = youtube.channels().list(\n",
        "      part='contentDetails', id=links\n",
        "    ).execute()\n",
        "\n",
        "    if 'items' in channelRes and channelRes['items']:\n",
        "      playlistId = channelRes['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "\n",
        "      playlistResult = youtube.playlistItems().list(\n",
        "        part='contentDetails', playlistId=playlistId,\n",
        "        maxResults = 100, pageToken = next_page_token\n",
        "      ).execute()\n",
        "\n",
        "      videoIds.extend([item['contentDetails']['videoId'] for item in playlistResult.get('items', [])])\n",
        "\n",
        "      next_page_token = playlistResult.get('nextPageToken')\n",
        "\n",
        "      if not next_page_token:\n",
        "        break\n",
        "\n",
        "  for ids in videoIds:\n",
        "    videoUrl = f\"https://www.youtube.com/watch?v={ids}\"\n",
        "    try:\n",
        "      raw_transcripts = []\n",
        "      try:\n",
        "        captions = YouTubeTranscriptApi.get_transcript(\n",
        "          ids, languages=['en'], preserve_formatting=True\n",
        "        )\n",
        "        if captions:\n",
        "          formatted_captions = [{'text': caption['text']} for caption in captions]\n",
        "          raw_transcripts.append(formatted_captions)\n",
        "          videoNo += 1\n",
        "          print(f\"Number of videos with valid captions are: {videoNo}\")\n",
        "        else:\n",
        "          continue\n",
        "      except TranscriptsDisabled as e:\n",
        "        print(F\"There was an error while getting the captions: {e}\")\n",
        "      except Exception as e:\n",
        "        logging.error(f\"There was some error while fetching the video: {str(e)}\")\n",
        "    except Exception as e:\n",
        "      logging.error(f\"There was some error while getting the captions: {str(e)}\")\n",
        "\n",
        "    with open('new_training_data.txt', 'a', encoding='utf-8') as file:\n",
        "      for videoCaptions in raw_transcripts:\n",
        "        for line in videoCaptions:\n",
        "          file.write(line['text'] + ' ')\n",
        "\n",
        "print(f\"time taken to execute the code is {(timeit.default_timer() - start_time) / 60} mins\")"
      ],
      "metadata": {
        "id": "tOr_lkpp5xz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_coll = timeit.default_timer()\n",
        "print(f\"time taken to fetch and write the data {(data_coll - start_time) / 3600} hrs\")"
      ],
      "metadata": {
        "id": "dl8MlyXb50pv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}