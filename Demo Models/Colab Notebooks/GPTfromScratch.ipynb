{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1GirIh-L3I0luR95oxwMP6x5nbwmPS7yk",
      "authorship_tag": "ABX9TyNFnv4fQFXkMv/R13Pv/LB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivendrra/SmallLanguageModel-project/blob/main/Demo%20Models/Colab%20Notebooks/GPTfromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**coding the tokenizer first**"
      ],
      "metadata": {
        "id": "1ewiBOXRgSLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a sub-word level tokenizer\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "class SubwordTokenizer:\n",
        "    def __init__(self, num_merges):\n",
        "        self.num_merges = num_merges\n",
        "        self.vocab = None\n",
        "\n",
        "    def get_stats(self, vocab):\n",
        "        pairs = defaultdict(int)\n",
        "        for word, freq in vocab.items():\n",
        "            symbols = word.split()\n",
        "            for i in range(len(symbols) - 1):\n",
        "                pairs[symbols[i], symbols[i+1]] += freq\n",
        "        return pairs\n",
        "\n",
        "    def merge_vocab(self, pair, vocab):\n",
        "        new_vocab = {}\n",
        "        bigram = ' '.join(pair)\n",
        "        replacement = ''.join(pair)\n",
        "        for word in vocab:\n",
        "            new_word = word.replace(bigram, replacement)\n",
        "            new_vocab[new_word] = vocab[word]\n",
        "        return new_vocab\n",
        "\n",
        "    def learn_bpe(self, data):\n",
        "        vocab = defaultdict(int)\n",
        "        for word in data:\n",
        "            vocab[''.join(list(word)) + '</w>'] += 1\n",
        "\n",
        "        for i in range(self.num_merges):\n",
        "            pairs = self.get_stats(vocab)\n",
        "            if not pairs:\n",
        "                break\n",
        "            best_pair = max(pairs, key=pairs.get)\n",
        "            vocab = self.merge_vocab(best_pair, vocab)\n",
        "\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def tokenize_generator(self, text):\n",
        "      if isinstance(text, list):\n",
        "        for word in text:\n",
        "            word = ' '.join(list(word))\n",
        "            if word in self.vocab:\n",
        "                yield word\n",
        "            else:\n",
        "                yield word[:2]  # yield the initial part of the word\n",
        "                yield from (word[i:i+2] for i in range(2, len(word), 2) if word[i:i+2] in self.vocab)\n",
        "      else:\n",
        "        word = ' '.join(list(text))\n",
        "        if word in self.vocab:\n",
        "            yield word\n",
        "        else:\n",
        "            yield word[:2]  # yield the initial part of the word\n",
        "            yield from (word[i:i+2] for i in range(2, len(word), 2) if word[i:i+2] in self.vocab)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "      return list(self.tokenize_generator(text))\n",
        "\n",
        "    def detokenize(self, tokens):\n",
        "        detokenized_txt = ''.join(tokens)\n",
        "        return detokenized_txt"
      ],
      "metadata": {
        "id": "G8tzESxE7xpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "nstQNTFXrWgJ",
        "outputId": "7ad0b011-8bf2-49fb-971c-11d88b594d6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data for training the BPE\n",
        "with open('/content/drive/MyDrive/training_data.txt', 'r', encoding='utf-8') as file:\n",
        "  captions = file.read()\n",
        "\n",
        "# tokenizing\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "token_caps = nltk.word_tokenize(captions)"
      ],
      "metadata": {
        "id": "32uyvCyC7i8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "n = int(0.8*len(token_caps))\n",
        "bpe_train_data = token_caps[:n]\n",
        "bpe_val_data = token_caps[n:]"
      ],
      "metadata": {
        "id": "fZuR1Kyw7qCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the tokenizer on the training data\n",
        "num_merges = 50\n",
        "tokenizer = SubwordTokenizer(num_merges)\n",
        "tokenizer.learn_bpe(bpe_train_data)"
      ],
      "metadata": {
        "id": "ZqLjUel46enL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing the data separately\n",
        "\n",
        "# normal tokenization first\n",
        "train_words = nltk.word_tokenize(train_data)\n",
        "val_words = nltk.word_tokenize(val_data)\n",
        "\n",
        "# sub-word tokenization in batches\n",
        "batch_size = 100\n",
        "trained_data = [tokenizer.tokenize(train_words[i:i+batch_size]) for i in range(0, len(train_words), batch_size)]\n",
        "valed_data = [tokenizer.tokenize(val_words[i:i+batch_size]) for i in range(0, len(val_words), batch_size)]"
      ],
      "metadata": {
        "id": "i4ny47xK6hhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten the batches\n",
        "trained_data = [token for batch in trained_data for token in batch]\n",
        "valed_data = [token for batch in valed_data for token in batch]"
      ],
      "metadata": {
        "id": "XkWk5xTbynHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[:10])\n",
        "print(tokenizer.detokenize(train_data[:10]))\n",
        "print(val_data[:10])\n",
        "print(tokenizer.detokenize(val_data[:10]))"
      ],
      "metadata": {
        "id": "KuCqNmT9z5He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main gpt starts from here**"
      ],
      "metadata": {
        "id": "tjANSNUf7kkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsPQTM7_6w99",
        "outputId": "55c6f2c7-c2be-4c3e-8f96-41fe5fbd1bf9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the data\n",
        "file_path = '/content/drive/MyDrive/new_training_data.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "  data = file.read()\n",
        "total_no_of_words = len(data)\n",
        "print(total_no_of_words)"
      ],
      "metadata": {
        "id": "lcZMRIKmq8Pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ec4a8b-8ed3-4e14-8b89-b56608405875"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219382798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total no of chars and vocab size\n",
        "chars = sorted(list(set(data)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "fy-eNUDesO6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6078f48c-e768-4def-f0a1-7afb8522b0c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡£­°²³´µ·¼½ÀÁÃÄÅÉÍÓÖ×ßàáâãäåæçèéêëìíîïñòóôõöøúüāăćČĐğīİŁłōśūŻʖʻʼ̴̵̶̷̸̡̢̧̨̛̖̗̘̙̜̝̞̟̠̣̤̥̦̩̪̫̬̭̮̯̰̱̲̳̹̺̻̼͇͈͉͍͎͓͔͕͖͙͚̀́̂̃̄̅̆̇̈̉̊̋̌̍̎̏̐̑̒̓̔̽̾̿̀́͂̓̈́͆͊͋͌͐͑͒͗͛̕̚͘͜͝͠͡ͅΧιρςστχόϑДಠ ​‍–—―‘’‚“”… ›‽⁠₂€₹™⅓⅔∆−≈⍵♩♪♫♬♭⚡✨。えァアウェオサシジスッデトナニビフブボメョリルロンー一万写動千夜如宇宏开忽春来树梨活真花萌风꞉️﻿，ａｄｅｇｈｉｍｎｒｔｕｖｙ�𝅘𝅥𝅮𝔻𝕄𝕌𝕐𝕒𝕓𝕔𝕕𝕖𝕗𝕘𝕙𝕚𝕛𝕜𝕝𝕞𝕟𝕠𝕡𝕢𝕣𝕤𝕥𝕦𝕧𝕨𝕪𝘐𝘢𝘣𝘤𝘥𝘦𝘧𝘩𝘪𝘭𝘮𝘯𝘰𝘱𝘳𝘴𝘵𝘶𝘸𝘺🔮🤔\n",
            "416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "NIh0X7Cspotc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "start_time_2 = timeit.default_timer()"
      ],
      "metadata": {
        "id": "YLGNbB0vltCY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder and decoder of the text\n",
        "string_to_index = { ch:i for i,ch in enumerate(chars) }\n",
        "index_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "encode = lambda s: [string_to_index[c] for c in s]\n",
        "decode = lambda l: ''.join([index_to_string[i] for i in l])\n",
        "\n",
        "print(encode('hello there'))\n",
        "print(decode(encode('hello there')))"
      ],
      "metadata": {
        "id": "N5Umz0p7g5ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e124d870-7007-4bc6-e3af-2641a138e3f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[73, 70, 77, 77, 80, 1, 85, 73, 70, 83, 70]\n",
            "hello there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = torch.tensor(encode(train_data), dtype=torch.long)\n",
        "val_data = torch.tensor(encode(val_data), dtype=torch.long)"
      ],
      "metadata": {
        "id": "O1u8_7v1daCC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[:20], len(train_data), len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgh5GfbI4djA",
        "outputId": "3c229db2-a74d-4bb9-a215-43fd3f429b91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([56, 73, 90,  1, 88, 70, 83, 70,  1, 85, 73, 70,  1, 88, 73, 70, 70, 77,\n",
            "        84,  1]) 197444518 21938280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main bigram transformer model**"
      ],
      "metadata": {
        "id": "XwuQZkih8ulf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 128 # independent sequences in parallel\n",
        "block_size = 256 # max context length for predictions\n",
        "max_iters = 5000\n",
        "eval_interval = 100 # after interval outputs\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "dropout = 0.3\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "steps = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        # Store step and loss values for visualization\n",
        "        steps.append(iter)\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['val'])\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "torch.save(model.state_dict(), 'large_parameter_transformer_model.pth')\n",
        "output_data = decode(m.generate(context, max_new_tokens=2000)[0].tolist())\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "id": "SRNw2nX3njOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41834a82-2953-4cfa-8ae3-96a6868e8433"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.058848 M parameters\n",
            "step 0: train loss 6.2578, val loss 6.2638\n",
            "step 100: train loss 2.4326, val loss 2.5175\n",
            "step 200: train loss 2.3537, val loss 2.4177\n",
            "step 300: train loss 2.0659, val loss 2.1179\n",
            "step 400: train loss 1.8053, val loss 1.8415\n",
            "step 500: train loss 1.6527, val loss 1.6787\n",
            "step 600: train loss 1.5503, val loss 1.5679\n",
            "step 700: train loss 1.4810, val loss 1.4929\n",
            "step 800: train loss 1.4324, val loss 1.4357\n",
            "step 900: train loss 1.3903, val loss 1.4002\n",
            "step 1000: train loss 1.3643, val loss 1.3790\n",
            "step 1100: train loss 1.3337, val loss 1.3404\n",
            "step 1200: train loss 1.3200, val loss 1.3248\n",
            "step 1300: train loss 1.3002, val loss 1.3054\n",
            "step 1400: train loss 1.2838, val loss 1.2884\n",
            "step 1500: train loss 1.2679, val loss 1.2741\n",
            "step 1600: train loss 1.2569, val loss 1.2589\n",
            "step 1700: train loss 1.2389, val loss 1.2435\n",
            "step 1800: train loss 1.2246, val loss 1.2317\n",
            "step 1900: train loss 1.2206, val loss 1.2210\n",
            "step 2000: train loss 1.2100, val loss 1.2164\n",
            "step 2100: train loss 1.2039, val loss 1.2045\n",
            "step 2200: train loss 1.1991, val loss 1.1984\n",
            "step 2300: train loss 1.1896, val loss 1.1918\n",
            "step 2400: train loss 1.1874, val loss 1.1868\n",
            "step 2500: train loss 1.1772, val loss 1.1761\n",
            "step 2600: train loss 1.1762, val loss 1.1702\n",
            "step 2700: train loss 1.1704, val loss 1.1660\n",
            "step 2800: train loss 1.1698, val loss 1.1641\n",
            "step 2900: train loss 1.1611, val loss 1.1635\n",
            "step 3000: train loss 1.1591, val loss 1.1537\n",
            "step 3100: train loss 1.1535, val loss 1.1516\n",
            "step 3200: train loss 1.1526, val loss 1.1461\n",
            "step 3300: train loss 1.1495, val loss 1.1462\n",
            "step 3400: train loss 1.1463, val loss 1.1422\n",
            "step 3500: train loss 1.1414, val loss 1.1391\n",
            "step 3600: train loss 1.1419, val loss 1.1349\n",
            "step 3700: train loss 1.1360, val loss 1.1308\n",
            "step 3800: train loss 1.1344, val loss 1.1320\n",
            "step 3900: train loss 1.1365, val loss 1.1299\n",
            "step 4000: train loss 1.1283, val loss 1.1234\n",
            "step 4100: train loss 1.1268, val loss 1.1219\n",
            "step 4200: train loss 1.1279, val loss 1.1195\n",
            "step 4300: train loss 1.1233, val loss 1.1184\n",
            "step 4400: train loss 1.1236, val loss 1.1159\n",
            "step 4500: train loss 1.1232, val loss 1.1117\n",
            "step 4600: train loss 1.1193, val loss 1.1124\n",
            "step 4700: train loss 1.1170, val loss 1.1134\n",
            "step 4800: train loss 1.1199, val loss 1.1121\n",
            "step 4900: train loss 1.1139, val loss 1.1074\n",
            "step 4999: train loss 1.1147, val loss 1.1082\n",
            "\n",
            "so reciting the batcore is here but I'm on a lot. Good files are not askward.orえ sympus consequence. So, we Theraarson Chinal China\n",
            "limited that is necess to hear the games yet to stop until in appearing. Okay. quite that one worth of the equal\n",
            "consequences a basical lenson that doesn't. The idea is that does it mean consider every\n",
            "catches with honest and of indicates how to give\n",
            "hopeful flight down and just 18 a basically bietook this\n",
            "essencing that doesn't could be doing anything that would work. Even with have betme. Now, but right now about you\n",
            "have bad and just two topic and so two of coding have two. But before we didn't even do. Let's just say, well, But let's\n",
            "do something to them include the file. So that's really height. Oh, this is the programming. We'll set something variable check but also\n",
            "converts for the debugs as long and this-- forwards essence\n",
            "counts, help and consider. Message counts oun on your\n",
            "lucks. Let's start water whater happened in the ethero the grater to help our becide slates, and not\n",
            "even complete efficience with networked likes. And this functional functions\n",
            "had the function, would. I hoped the arrivative mass called So else focus\n",
            "in durable resembled or proper tabs that like, 500 and \"ProPre-minicans\";.... I also should now style hey go nookward code. (nollooking fund in part of VD pul-min Ross) [it] [? wharacter [it] [itins] ♪ blockward and then Motor Bush owns-Hush Orego\n",
            "wards against yet looking\n",
            "into liest out of along there's any violence. (communicatity). And so here, no transform transforms to how to make? Somewhere, and there's a bolk for us\n",
            "and D * 20 Mountains’ Mountain screen verriched, hzm were a room for lilbox-sedimagories. A part-get, under screens where she's worked in San Yome within the linbox is my R. From one and whites us body\n",
            "the year undernitune. But it’s my season, it's going too. And her co-eten-inietically effective. The Batheor is but more\n",
            "disable than Prik. But I’d see mystline might import so it’s promised t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_train = timeit.default_timer()\n",
        "\n",
        "print(f\"time taken to train the model {(model_train - start_time_2) / 3600 } hrs\")"
      ],
      "metadata": {
        "id": "KRSkGZd8pbgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e24805-b7a0-423f-9b9d-daaf206052e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken to train the model 1.0235756409075 hrs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(steps, train_losses, label='Train Loss')\n",
        "plt.plot(steps, val_losses, label='Validation Loss')\n",
        "plt.title('Loss Over Steps')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fvbzqc4Mvnrw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "f34160ea-3a35-4bd9-8403-fa06d4da68c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary\n",
        "end_time = timeit.default_timer()\n",
        "\n",
        "total_time = (end_time - start_time_2) / 3600\n",
        "\n",
        "ffn_factor = 4\n",
        "embedding_params = n_embd * vocab_size\n",
        "attention_params = n_head * (n_embd // n_head * 2 * n_embd) * n_layer\n",
        "\n",
        "feedforward_params = n_embd * ffn_factor * n_layer * 2\n",
        "total_param = sum(p.numel() for p in m.parameters()) / 1e6\n",
        "total_params = embedding_params + attention_params + feedforward_params\n",
        "\n",
        "print(\"///// summary /////\")\n",
        "# print(f\"time just to fetch the data was {(data_coll - start_time) / 3600} hrs and no of videos fetched were {videoNo}\")\n",
        "print(f\"total no of words in the file were: {total_no_of_words/1e6} million\")\n",
        "print(f\"total vocab size was {vocab_size}\")\n",
        "print(\"total no of calculated parameters:\", total_params)\n",
        "print(\"total no of actual parameters:\", total_param)\n",
        "print(f\"time taken to train the model was {(model_train - start_time_2) / 3600} hrs\")\n",
        "print(f\"model ran for {max_iters} iterations and final val loss: {val_losses[-1]} and train loss: {train_losses[-1]}\")\n",
        "print('\\n', '\\n')\n",
        "print(\"//// generated output ////\")\n",
        "print(output_data)"
      ],
      "metadata": {
        "id": "DetNldUaw_Ze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b627f5a0-c21f-4061-db53-f8eb3d9ff13e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "///// summary /////\n",
            "total no of words in the file were: 219.382798 million\n",
            "total vocab size was 416\n",
            "total no of calculated parameters: 1947648\n",
            "total no of actual parameters: 11.058848\n",
            "time taken to train the model was 1.0235756409075 hrs\n",
            "model ran for 5000 iterations and final val loss: 1.1082205772399902 and train loss: 1.114668369293213\n",
            "\n",
            " \n",
            "\n",
            "//// generated output ////\n",
            "\n",
            "in his energy browality Trop his crue she\n",
            "is a 1-year-tempi energy Poster. Especially, posters she researching the animator of\n",
            "the resitants, but a ‘earer for fordunately we she sounds the copies \n",
            "for comed this. the weddie showerfig\n",
            "the cruewired second in instealed himself,\n",
            "Ohio. There was I-special headiet. The company. \"Constraine Twine ireleva. Both the shooths assistational his sonscientific increased users who will just\n",
            "leave that allies bone. And these geod, who might receigned likelins\n",
            "agreed to piece a repeat of friends\n",
            "our next weark sets in Russian. SafeCial Warn\n",
            "to be coming, and as many differences of\n",
            "likels have ding. On a couple of likesit likely. Hipplifying, a coursectors\n",
            "let's their hand. They\n",
            "will undeestly in how for low-lever differentless”, and government war, and safestions depressite. Now there are she\n",
            "are no work, and update killeds to emphasize drimns. War that Dwim%. How does they still play undersbate\n",
            "viewed sheets into between troubled tasks — asks-five thousands \n",
            "eners that distributes with it. Now we swear the   under datation do there we decide to mention what\n",
            "goes to sheet to build   on my nose. There will dissciously changes though \n",
            "is part of the weather number time and matter not the worse \n",
            "genuine flowing that we read on the most time bets   can do that. However, many of sounds, many other \n",
            "important won't have nose rip would a flower   color by whise, this, this time appli, ever if I want to do \n",
            "ourselves we're source idly more than continsite in absention or stuff.   I'll they're in the flowers,\n",
            "continuing which big love over   two blowers. Honestly what's not only very \n",
            "shipped. Well, mean. I do. \n",
            " - This \n",
            "is my new resours claimed like of those resourcembers coming with  these loues, welcome between my new blowers with all\n",
            "business, and engaging greens at the top-of-like \n",
            "is light basically like Cpadox, these are repovered in   the necosystems togeth. It is like budge and \n",
            "25 billions of skyllmer is \n",
            "investment in and having\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = BigramLanguageModel()\n",
        "loaded_model.load_state_dict(torch.load('large_parameter_transformer_model.pth'))\n",
        "loaded_model.to(device)\n",
        "\n",
        "# Print detailed information about the model's state dictionary\n",
        "for name, param in loaded_model.named_parameters():\n",
        "    print(f'{name}: {param.shape}, {param.numel()} parameters')"
      ],
      "metadata": {
        "id": "tKGmtIKHnFIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaab7ce4-2017-46e4-eefe-1cb91c9aec4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_embedding_table.weight: torch.Size([416, 384]), 159744 parameters\n",
            "position_embedding_table.weight: torch.Size([256, 384]), 98304 parameters\n",
            "blocks.0.sa.heads.0.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.0.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.0.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.1.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.1.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.1.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.2.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.2.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.2.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.3.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.3.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.3.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.4.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.4.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.4.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.5.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.5.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.5.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.6.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.6.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.6.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.7.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.7.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.heads.7.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.0.sa.proj.weight: torch.Size([384, 384]), 147456 parameters\n",
            "blocks.0.sa.proj.bias: torch.Size([384]), 384 parameters\n",
            "blocks.0.ffwd.net.0.weight: torch.Size([1536, 384]), 589824 parameters\n",
            "blocks.0.ffwd.net.0.bias: torch.Size([1536]), 1536 parameters\n",
            "blocks.0.ffwd.net.2.weight: torch.Size([384, 1536]), 589824 parameters\n",
            "blocks.0.ffwd.net.2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.0.ln1.weight: torch.Size([384]), 384 parameters\n",
            "blocks.0.ln1.bias: torch.Size([384]), 384 parameters\n",
            "blocks.0.ln2.weight: torch.Size([384]), 384 parameters\n",
            "blocks.0.ln2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.1.sa.heads.0.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.0.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.0.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.1.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.1.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.1.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.2.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.2.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.2.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.3.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.3.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.3.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.4.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.4.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.4.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.5.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.5.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.5.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.6.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.6.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.6.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.7.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.7.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.heads.7.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.1.sa.proj.weight: torch.Size([384, 384]), 147456 parameters\n",
            "blocks.1.sa.proj.bias: torch.Size([384]), 384 parameters\n",
            "blocks.1.ffwd.net.0.weight: torch.Size([1536, 384]), 589824 parameters\n",
            "blocks.1.ffwd.net.0.bias: torch.Size([1536]), 1536 parameters\n",
            "blocks.1.ffwd.net.2.weight: torch.Size([384, 1536]), 589824 parameters\n",
            "blocks.1.ffwd.net.2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.1.ln1.weight: torch.Size([384]), 384 parameters\n",
            "blocks.1.ln1.bias: torch.Size([384]), 384 parameters\n",
            "blocks.1.ln2.weight: torch.Size([384]), 384 parameters\n",
            "blocks.1.ln2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.2.sa.heads.0.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.0.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.0.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.1.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.1.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.1.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.2.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.2.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.2.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.3.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.3.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.3.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.4.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.4.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.4.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.5.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.5.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.5.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.6.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.6.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.6.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.7.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.7.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.heads.7.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.2.sa.proj.weight: torch.Size([384, 384]), 147456 parameters\n",
            "blocks.2.sa.proj.bias: torch.Size([384]), 384 parameters\n",
            "blocks.2.ffwd.net.0.weight: torch.Size([1536, 384]), 589824 parameters\n",
            "blocks.2.ffwd.net.0.bias: torch.Size([1536]), 1536 parameters\n",
            "blocks.2.ffwd.net.2.weight: torch.Size([384, 1536]), 589824 parameters\n",
            "blocks.2.ffwd.net.2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.2.ln1.weight: torch.Size([384]), 384 parameters\n",
            "blocks.2.ln1.bias: torch.Size([384]), 384 parameters\n",
            "blocks.2.ln2.weight: torch.Size([384]), 384 parameters\n",
            "blocks.2.ln2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.3.sa.heads.0.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.0.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.0.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.1.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.1.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.1.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.2.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.2.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.2.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.3.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.3.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.3.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.4.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.4.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.4.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.5.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.5.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.5.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.6.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.6.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.6.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.7.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.7.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.heads.7.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.3.sa.proj.weight: torch.Size([384, 384]), 147456 parameters\n",
            "blocks.3.sa.proj.bias: torch.Size([384]), 384 parameters\n",
            "blocks.3.ffwd.net.0.weight: torch.Size([1536, 384]), 589824 parameters\n",
            "blocks.3.ffwd.net.0.bias: torch.Size([1536]), 1536 parameters\n",
            "blocks.3.ffwd.net.2.weight: torch.Size([384, 1536]), 589824 parameters\n",
            "blocks.3.ffwd.net.2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.3.ln1.weight: torch.Size([384]), 384 parameters\n",
            "blocks.3.ln1.bias: torch.Size([384]), 384 parameters\n",
            "blocks.3.ln2.weight: torch.Size([384]), 384 parameters\n",
            "blocks.3.ln2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.4.sa.heads.0.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.0.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.0.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.1.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.1.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.1.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.2.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.2.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.2.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.3.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.3.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.3.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.4.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.4.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.4.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.5.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.5.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.5.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.6.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.6.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.6.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.7.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.7.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.heads.7.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.4.sa.proj.weight: torch.Size([384, 384]), 147456 parameters\n",
            "blocks.4.sa.proj.bias: torch.Size([384]), 384 parameters\n",
            "blocks.4.ffwd.net.0.weight: torch.Size([1536, 384]), 589824 parameters\n",
            "blocks.4.ffwd.net.0.bias: torch.Size([1536]), 1536 parameters\n",
            "blocks.4.ffwd.net.2.weight: torch.Size([384, 1536]), 589824 parameters\n",
            "blocks.4.ffwd.net.2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.4.ln1.weight: torch.Size([384]), 384 parameters\n",
            "blocks.4.ln1.bias: torch.Size([384]), 384 parameters\n",
            "blocks.4.ln2.weight: torch.Size([384]), 384 parameters\n",
            "blocks.4.ln2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.5.sa.heads.0.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.0.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.0.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.1.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.1.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.1.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.2.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.2.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.2.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.3.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.3.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.3.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.4.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.4.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.4.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.5.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.5.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.5.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.6.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.6.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.6.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.7.key.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.7.query.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.heads.7.value.weight: torch.Size([48, 384]), 18432 parameters\n",
            "blocks.5.sa.proj.weight: torch.Size([384, 384]), 147456 parameters\n",
            "blocks.5.sa.proj.bias: torch.Size([384]), 384 parameters\n",
            "blocks.5.ffwd.net.0.weight: torch.Size([1536, 384]), 589824 parameters\n",
            "blocks.5.ffwd.net.0.bias: torch.Size([1536]), 1536 parameters\n",
            "blocks.5.ffwd.net.2.weight: torch.Size([384, 1536]), 589824 parameters\n",
            "blocks.5.ffwd.net.2.bias: torch.Size([384]), 384 parameters\n",
            "blocks.5.ln1.weight: torch.Size([384]), 384 parameters\n",
            "blocks.5.ln1.bias: torch.Size([384]), 384 parameters\n",
            "blocks.5.ln2.weight: torch.Size([384]), 384 parameters\n",
            "blocks.5.ln2.bias: torch.Size([384]), 384 parameters\n",
            "ln_f.weight: torch.Size([384]), 384 parameters\n",
            "ln_f.bias: torch.Size([384]), 384 parameters\n",
            "lm_head.weight: torch.Size([416, 384]), 159744 parameters\n",
            "lm_head.bias: torch.Size([416]), 416 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_PK2Jgw27wA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}